from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

model_name = "MBZUAI/LaMini-Flan-T5-783M"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

corrector = pipeline("text2text-generation", model=model, tokenizer=tokenizer)

ocr_text = "‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶ö‡¶ï‡¶≤‡¶¶‡¶æ‡¶∞‡•§ ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶ú ‡¶ú‡¶® ‡¶õ‡¶æ‡¶§‡ßç‡¶∞‡•§"
prompt = f"‡¶∂‡ßÅ‡¶¶‡ßç‡¶ß ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶¨‡¶æ‡¶®‡¶æ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶∞‡¶£‡ßá ‡¶†‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®: {ocr_text}"

result = corrector(prompt, max_new_tokens=100)

print("üî§ Original OCR Text:")
print(ocr_text)
print("\n‚úÖ Corrected Text:")
print(result[0]['generated_text'])
